[[{"l":"Project Silox","p":["License: CC BY-NC-ND 4.0 Python 3.11 Django 4.2 Docker Docker"]},{"l":"License","p":["The project is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/."]},{"l":"Context","p":["SiouxSilos Itd. is a company that manufactures industrial bulk and liquid materials storage systems. It commissioned us to design and implement a solution suitable for monitoring and managing the level of materials contained in the silos of an industrial plant built in North Dakota.","Each tank is equipped with 8 sensors (S) positioned on the inner side of the tank at the distance of 1 m each. On the outside, one meter from the base and at the top, one humidity sensor and one temperature sensor are placed. There are seven tanks in total, divided into two blocks of 3 and 4, located in two areas of the plant about 150 meters apart.","The solution should be able to:","acquire, through a PLC, the data detected by the sensors, calculating the quantities of material present in the silos, displaying the most relevant data in a display;","provide an alarm if the tank level exceeds the lower and upper reference thresholds;","manage, again through PLC, a shutter for loading/emptying silos;","send data to cloud, through a gateway, handling situations of absence or loss of internet connectivity, and showing data trends in graphical form with a web page."]},{"l":"What we did","p":["We have developed a solution that consists of three main modules:","REST API: it is a Django application that allows you to manage the database and run the simulators.","Simulator: it is a python script that simulates the data sent by the sensors.","Ingester: it is a python script that subscribes to the MQTT broker and saves the data in the influxdb database.","All the modules work autonomously and communicate with each other through the MQTT protocol. In this way, it is possible to simulate the data and send them to the database without having to use the PLC."]},{"l":"How to start the project","p":["To start the project you need to have docker and docker-compose installed on your machine. Then you need to run docker-compose --env-file .env up --build"]}],[{"l":"Backend","p":["The Backend was developed in python and consists of 3 main modules: REST API, Simulator, ingester. These 3 modules work autonomously and communicate with each other through the MQTT protocol."]},{"l":"System map"},{"l":"The modules"},{"l":"API Module","p":["The API was written in python using Django and the Django Rest Framework library. The APIs are used to manage the database and run the Silos simulators."]},{"l":"Simulator Module","p":["The simulator connects to the MQTT broker, when the frontend sends the command that contains the data of the silos Then a thread is started that begins to send a series of data via MQTT to a broker."]},{"l":"Ingestor Module","p":["The ingester is a python script that subscribes to the MQTT broker and saves the data in the influxdb database."]}],[{"l":"REST API Module"},{"l":"API Module","p":["The API was written in python using Django and the Django Rest Framework library. The APIs are used to manage the database and run the Silos simulators."]},{"l":"How it works","p":["Django provides a series of endpoints that can be used to manage the database and run the simulators.","When the frontend sends a request to the API, the API will process the request and send the data to the MQTT broker.","The MQTT broker will then send the data to the simulator, which will start sending the data. The ingester will then save the data in influxDB."]},{"l":"How to start Django in DEV mode","p":["All the project is still in the DEV stage so to start it you just need to go to the backend/api folder and start the project with python manage.py runserver","This way you will only be able to access it from http://127.0.0.1:8000. If you want to start it so that it can be reached from other computers as well start it with python manage.py runserver 0.0.0.0:8000"]},{"l":"Docker entrypoint","p":["The docker entrypoint is a script that starts the Django server. It also creates the database tables and the admin user and create the migrations."]},{"l":"How to use the API","p":["The API is documented with swagger and can be reached at https://api.projectsilox.ml/schema/swagger-ui/"]}],[{"l":"Simulator Module","p":["The simulator connects to the MQTT broker, when the frontend sends the command that contains the data of the silos Then a thread is started that begins to send a series of data via MQTT to a broker."]},{"l":"How to start the simulator","p":["To start the simulator you need to have python 3.11 installed on your machine. Then you need to install the requirements with pip install -r requirements.txt Then you need to enter the backend/simulator folder and start the simulator with python main.py"]},{"l":"How to start dockerized simulator","p":["To start the simulator in docker you need to have docker and docker-compose installed on your machine. Then you need to run docker-compose --env-file .env up --build"]},{"l":"How to use the simulator","p":["To use the simulator you need to send a command to the MQTT broker. The command must be sent to the topic t/simulator/silos/{silos_id}/command/start where {silos_id} is the id of the silo. The payload of the command must be a json object that contains the data of the silo."]}],[{"l":"Ingester Module","p":["The ingester is a python script that subscribes to the MQTT broker and saves the data in the influxdb database."]},{"l":"How to start the ingester","p":["To start the ingester you need to have python 3.11 installed on your machine. Then you need to install the requirements with pip install -r requirements.txt Then you need to enter the backend/ingester folder and start the ingester with python main.py"]}],[{"l":"MQTT Broker","p":["The MQTT broker is used to send data from the simulator to the ingester and the frontend. The broker used is EMQX because it is open source and easy to use."]},{"l":"Subscribe Topics","p":["{kill: true, id: silos_id}","{percentage: 0}","{percentage: 100}","data serialized from DB","Description","Empty the silo","Fill the silo","Kill the simulator","Payload","Set the simulator in idle mode(level sensor does not change while other sensors continue to send data)","Start the simulator","Stop the simulator","t/simulator/silos/<silos_id>/command/empty","t/simulator/silos/<silos_id>/command/fill","t/simulator/silos/<silos_id>/command/idle","t/simulator/silos/<silos_id>/command/kill","t/simulator/silos/<silos_id>/command/start","t/simulator/silos/<silos_id>/command/stop","The MQTT topics used by the system are listed below.","Topic"]},{"l":"Publish Topics","p":["Topic","Description","t/simulator/silos/<silos_id>/measurements/","Send the measurements of the silo identified by the <silos_id>. The slug can be level, temperature, humidity, weight, pressure, filling_percentage"]}],[{"l":"Database","p":["Considering the data we are going to save will be temporal data, we used two databases:","Postgresql: for static data such as silo, liquids, sensors, etc.","Influxdb: for data that comes to us directly from sensors in real time and that we will use to make graphs and statistics."]}],[{"l":"PostgreSQL","p":["The database used is PostgreSQL, it is a relational database that is used to store the data of the silos and the users.","The records are managed by the API module, which exposes the REST APIs to the frontend."]},{"l":"Database schema"}],[{"l":"InfluxDB","p":["The database used is InfluxDB, it is a time series database that is used to store the data of the sensors.","The measurements are saved by the ingester in the database and then they are used by the frontend to make graphs and statistics."]}],[{"l":"Frontend"}]]